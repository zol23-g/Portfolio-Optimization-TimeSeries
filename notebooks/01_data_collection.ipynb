{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook, we demonstrate the process of collecting and preprocessing historical financial data using the `yfinance` library.\n",
    "\n",
    "### Steps:\n",
    "1. **Data Collection**:\n",
    "   - We use the `fetch_data` function to retrieve data for Tesla (TSLA), Vanguard Total Bond Market ETF (BND), and S&P 500 ETF (SPY).\n",
    "   - The data includes daily metrics such as Open, High, Low, Close, Volume, and Adjusted Close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Data Cleaning**:\n",
    "   - The `clean_data` function handles missing data by dropping rows with any `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs:\n",
    "- Processed CSV files for each asset saved to the `/data` directory for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.append('../src/data_preprocessing')  # Ensure Python can find the module\n",
    "from data_processing import fetch_data, clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data collection\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2024-10-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA data processed and saved as TSLA_cleaned.csv\n",
      "BND data processed and saved as BND_cleaned.csv\n",
      "SPY data processed and saved as SPY_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch and process the data\n",
    "raw_data = fetch_data(tickers, start_date, end_date)\n",
    "\n",
    "# Iterate through the fetched data, clean it, and save the cleaned version\n",
    "for ticker, df in raw_data.items():\n",
    "    df_cleaned = clean_data(df)\n",
    "    df_cleaned.to_csv(f'../data/{ticker}_cleaned.csv', index=True)\n",
    "    print(f\"{ticker} data processed and saved as {ticker}_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
